{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9587bdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73e5346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/calebschaefer/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "734a75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import ssl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Embedding \n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b1306b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/calebschaefer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download's the stop word's\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c47e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset parquet (/Users/calebschaefer/.cache/huggingface/datasets/parquet/yelp_review_full-9c7006f5a2e02666/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31258eb71c1b43a2983290724062c8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>dr. goldberg offers everything i look for in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Got a letter in the mail last week that said D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649995</th>\n",
       "      <td>4</td>\n",
       "      <td>I had a sprinkler that was gushing... pipe bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649996</th>\n",
       "      <td>0</td>\n",
       "      <td>Phone calls always go to voicemail and message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649997</th>\n",
       "      <td>0</td>\n",
       "      <td>Looks like all of the good reviews have gone t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649998</th>\n",
       "      <td>4</td>\n",
       "      <td>I was able to once again rely on Yelp to provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649999</th>\n",
       "      <td>0</td>\n",
       "      <td>I have been using this company for 11 months. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0           4  dr. goldberg offers everything i look for in a...\n",
       "1           1  Unfortunately, the frustration of being Dr. Go...\n",
       "2           3  Been going to Dr. Goldberg for over 10 years. ...\n",
       "3           3  Got a letter in the mail last week that said D...\n",
       "4           0  I don't know what Dr. Goldberg was like before...\n",
       "...       ...                                                ...\n",
       "649995      4  I had a sprinkler that was gushing... pipe bro...\n",
       "649996      0  Phone calls always go to voicemail and message...\n",
       "649997      0  Looks like all of the good reviews have gone t...\n",
       "649998      4  I was able to once again rely on Yelp to provi...\n",
       "649999      0  I have been using this company for 11 months. ...\n",
       "\n",
       "[650000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dp_train = dataset['train'].to_pandas()\n",
    "dp_test = dataset['test'].to_pandas()\n",
    "dp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d33f40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess's the text data\n",
    "#by removing stop words and leading spaces \n",
    "#this data pre-process was inspired by: https://www.kaggle.com/code/gcdatkin/gru-hotel-rating-prediction\n",
    "def pre_process_data(X):\n",
    "    stop_words = stopwords.words('english')\n",
    "    X = re.sub(r'\\d+', ' ', X)\n",
    "    X = X.split()\n",
    "    X = \" \".join([word for word in X if word.lower().strip() not in stop_words])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "057965f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         dr. goldberg offers everything look general pr...\n",
       "1         Unfortunately, frustration Dr. Goldberg's pati...\n",
       "2         going Dr. Goldberg years. think one st patient...\n",
       "3         Got letter mail last week said Dr. Goldberg mo...\n",
       "4         know Dr. Goldberg like moving Arizona, let tel...\n",
       "                                ...                        \n",
       "649995    sprinkler gushing... pipe broken way ground, t...\n",
       "649996    Phone calls always go voicemail messages retur...\n",
       "649997    Looks like good reviews gone head place! Jason...\n",
       "649998    able rely Yelp provide needed response leaking...\n",
       "649999    using company months. Ryan would come every we...\n",
       "Name: text, Length: 650000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = dp_train['text'].apply(pre_process_data)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45afc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_words = 15000\n",
    "\n",
    "#takes the top 10,000 most used word's so we don't have the entire vocab\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1c0b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n"
     ]
    }
   ],
   "source": [
    "#get the length of the largest sequnces\n",
    "max_length = np.max(list(map(lambda x: len(x), sequences)))\n",
    "#pad all the input's to be the same length of the max length\n",
    "print(max_length)\n",
    "inputs = pad_sequences(sequences, maxlen=max_length, padding = 'post')\n",
    "labels = np.array(dp_train['label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, train_size=0.80, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d8a83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorlflow mlp was inspired from their website\n",
    "# ttps://www.tensorflow.org/guide/core/mlp_core and #https://www.geeksforgeeks.org/multi-layer-perceptron-learning-in-tensorflow\n",
    "#input_shape = tf.keras.Input(shape=(max_length,))\n",
    "#We want to use an embedding so the neural network is better able to differniate words\n",
    "model = Sequential([\n",
    "    #set's the input to be the size of the text (which is the max-length)\n",
    "    Embedding(input_dim = num_words, output_dim = 256),\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    \n",
    "    #output layer\n",
    "    Dense(5, activation = 'softmax'),\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "046d568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4816s\u001b[0m 296ms/step - accuracy: 0.5088 - loss: 1.0918\n",
      "Epoch 2/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6092s\u001b[0m 375ms/step - accuracy: 0.6447 - loss: 0.8211\n",
      "Epoch 3/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9319s\u001b[0m 573ms/step - accuracy: 0.7603 - loss: 0.5777\n",
      "Epoch 4/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4771s\u001b[0m 294ms/step - accuracy: 0.8452 - loss: 0.3883\n",
      "Epoch 5/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5889s\u001b[0m 362ms/step - accuracy: 0.8930 - loss: 0.2749\n",
      "Epoch 6/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5997s\u001b[0m 369ms/step - accuracy: 0.9223 - loss: 0.2043\n",
      "Epoch 7/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5915s\u001b[0m 364ms/step - accuracy: 0.9408 - loss: 0.1570\n",
      "Epoch 8/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5915s\u001b[0m 364ms/step - accuracy: 0.9534 - loss: 0.1249\n",
      "Epoch 9/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4815s\u001b[0m 296ms/step - accuracy: 0.9625 - loss: 0.1006\n",
      "Epoch 10/10\n",
      "\u001b[1m16250/16250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4776s\u001b[0m 294ms/step - accuracy: 0.9689 - loss: 0.0850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ed7e9850>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc1bd94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/calebschaefer/Documents/comp_5600/term_project/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/calebschaefer/Documents/comp_5600/term_project/model3/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"/Users/calebschaefer/Documents/comp_5600/term_project/model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fb7b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 23ms/step - accuracy: 0.5292 - loss: 3.4884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5062315464019775, 0.526761531829834]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6252ee77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        got 'new' tires within two weeks got flat. too...\n",
       "1        waste time. two different people come house gi...\n",
       "2        say worst! people place lunch, place freezing ...\n",
       "3        restaurant twice disappointed times. go back. ...\n",
       "4        Food GOOD all! husband & ate couple weeks ago ...\n",
       "                               ...                        \n",
       "49995    wanted write review chip others said. would re...\n",
       "49996    Great ambience. Great drinks. Great food. love...\n",
       "49997    Monks locations excited heard coming Sun Prair...\n",
       "49998    go here. know might want try good reviews peop...\n",
       "49999    Buffet recently open renovation husband thinki...\n",
       "Name: text, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews = dp_test['text'].apply(pre_process_data)\n",
    "test_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "085c53f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  17, 2237,  721, ...,    0,    0,    0],\n",
       "       [ 820,    8,   46, ...,    0,    0,    0],\n",
       "       [  65,  352,   28, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [1220,  641,  496, ...,    0,    0,    0],\n",
       "       [  12,   63,   41, ...,    0,    0,    0],\n",
       "       [ 235,  727,  236, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(test_reviews)\n",
    "#max_length = np.max(list(map(lambda x: len(x), sequences)))\n",
    "#print(max_length)\n",
    "#pad all the input's to be the same length of the max length\n",
    "test_inputs = pad_sequences(sequences, maxlen=855, padding = 'post')\n",
    "test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7214d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000, 855)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.asarray(dp_test['label'])\n",
    "print(y_test.shape)\n",
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcc0a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.4919 - loss: 2.3134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.275451898574829, 0.5008999705314636]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_inputs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7370ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
