{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ces0157/AI_class_project/blob/Sarah/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "b9909d01932bce0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "id": "rymr08RyEs7P"
   },
   "id": "rymr08RyEs7P"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5f16cf",
   "metadata": {
    "id": "ea5f16cf",
    "outputId": "e074c367-014d-4134-f209-8d51c5e3e543",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-04-17T22:16:07.878463Z",
     "start_time": "2024-04-17T22:16:00.736303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f84d2a",
   "metadata": {
    "id": "74f84d2a",
    "outputId": "433a3375-4f6a-416b-a985-a96d6c5a3e60",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-04-17T22:16:13.768748Z",
     "start_time": "2024-04-17T22:16:07.882472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install nltk"
   ],
   "metadata": {
    "id": "zNWGNrh-K2kL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7b3bf3b1-d474-42f3-c425-b7681e807fdb",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:16:18.960214Z",
     "start_time": "2024-04-17T22:16:13.772758Z"
    }
   },
   "id": "zNWGNrh-K2kL",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bingh\\onedrive\\documents\\school\\spring24\\5600\\ai_class_project\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7760c6",
   "metadata": {
    "id": "6f7760c6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "faefa337-0ed0-44fa-ce83-b053428fe5a5",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:16:30.216876Z",
     "start_time": "2024-04-17T22:16:18.967224Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bingh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all nesseccary import statements\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "id": "qExYOvL_EwKz"
   },
   "id": "qExYOvL_EwKz"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67603e72",
   "metadata": {
    "id": "67603e72",
    "outputId": "2ed5b4e1-7a5d-4abb-bc0f-2800a9f3a1ea",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-04-17T22:16:48.677774Z",
     "start_time": "2024-04-17T22:16:30.222886Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the dataset and split into testing and training\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dp_train = dataset['train'].to_pandas()\n",
    "dp_test = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fcf779",
   "metadata": {
    "id": "64fcf779",
    "outputId": "a260393d-4990-4260-ed33-cfd1e17ee192",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "ExecuteTime": {
     "end_time": "2024-04-17T22:16:48.738861Z",
     "start_time": "2024-04-17T22:16:48.683787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        label                                               text\n0           4  dr. goldberg offers everything i look for in a...\n1           1  Unfortunately, the frustration of being Dr. Go...\n2           3  Been going to Dr. Goldberg for over 10 years. ...\n3           3  Got a letter in the mail last week that said D...\n4           0  I don't know what Dr. Goldberg was like before...\n...       ...                                                ...\n649995      4  I had a sprinkler that was gushing... pipe bro...\n649996      0  Phone calls always go to voicemail and message...\n649997      0  Looks like all of the good reviews have gone t...\n649998      4  I was able to once again rely on Yelp to provi...\n649999      0  I have been using this company for 11 months. ...\n\n[650000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>dr. goldberg offers everything i look for in a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Unfortunately, the frustration of being Dr. Go...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Got a letter in the mail last week that said D...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I don't know what Dr. Goldberg was like before...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>649995</th>\n      <td>4</td>\n      <td>I had a sprinkler that was gushing... pipe bro...</td>\n    </tr>\n    <tr>\n      <th>649996</th>\n      <td>0</td>\n      <td>Phone calls always go to voicemail and message...</td>\n    </tr>\n    <tr>\n      <th>649997</th>\n      <td>0</td>\n      <td>Looks like all of the good reviews have gone t...</td>\n    </tr>\n    <tr>\n      <th>649998</th>\n      <td>4</td>\n      <td>I was able to once again rely on Yelp to provi...</td>\n    </tr>\n    <tr>\n      <th>649999</th>\n      <td>0</td>\n      <td>I have been using this company for 11 months. ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>650000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_train"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "id": "m_M-2EyrEzho"
   },
   "id": "m_M-2EyrEzho"
  },
  {
   "cell_type": "code",
   "source": [
    "# Creates a count vectorizer with vocab from training data\n",
    "def create_vectorizer(train_df, column_text):\n",
    "    sentences = train_df[column_text].values\n",
    "    vectorizer = CountVectorizer()  # add stop words here instead?\n",
    "\n",
    "    df = train_df.drop(columns=[column_text])\n",
    "\n",
    "    # fit the vocabulary to the text data\n",
    "    vectorizer.fit(sentences)\n",
    "    print(f'Vocab length: {len(vectorizer.vocabulary_.keys())}')\n",
    "\n",
    "    return vectorizer"
   ],
   "metadata": {
    "id": "GXm3ZUPeEgzA",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:41:59.799287Z",
     "start_time": "2024-04-17T22:41:59.789899Z"
    }
   },
   "id": "GXm3ZUPeEgzA",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbfe93ce",
   "metadata": {
    "id": "fbfe93ce",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:42:01.021629Z",
     "start_time": "2024-04-17T22:42:01.012239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Passes in dataframe column, converts it a numpy array\n",
    "# and performs the bag of word algorithm on it using vocab from training data\n",
    "# Returns a sparse matrix\n",
    "def create_bag_words(df, vectorizer, column_text):\n",
    "    sentences = df[column_text].values\n",
    "    df = df.drop(columns=[column_text])\n",
    "\n",
    "    # create the bag-of-words model using previously-created vectorizer\n",
    "    X = vectorizer.transform(sentences)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Data"
   ],
   "metadata": {
    "id": "sYLu_4Z6EWQ_"
   },
   "id": "sYLu_4Z6EWQ_"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57ef0f57",
   "metadata": {
    "id": "57ef0f57",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:42:03.064763Z",
     "start_time": "2024-04-17T22:42:03.054520Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = dp_train[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Removes stop words from training data and makes everything lowercase\n",
    "dp_train['no_stops'] = dp_train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "dp_train['no_stops'] = dp_train['no_stops'].str.lower()"
   ],
   "metadata": {
    "id": "S-GLaQXTJ09y",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:42:34.070061Z",
     "start_time": "2024-04-17T22:42:04.323395Z"
    }
   },
   "id": "S-GLaQXTJ09y",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ead552ea",
   "metadata": {
    "id": "ead552ea",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:45:44.328229Z",
     "start_time": "2024-04-17T22:42:34.074071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length: 242886\n"
     ]
    }
   ],
   "source": [
    "# create vectorizer consisting of vocab from training data\n",
    "vectorizer = create_vectorizer(dp_train, \"no_stops\")\n",
    "\n",
    "# Creates a set of new features modified to be a bag of words\n",
    "X_fetaures_train = create_bag_words(dp_train, vectorizer, \"no_stops\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(X_fetaures_train.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djzg8jSnRh2A",
    "outputId": "096ba59b-4bb0-4d23-9545-99adddff79da",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:25:06.508347Z",
     "start_time": "2024-04-17T22:25:06.507346Z"
    }
   },
   "id": "djzg8jSnRh2A",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fc9ed",
   "metadata": {
    "id": "614fc9ed",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "outputId": "a0dd8162-a377-4e37-9a55-cdcf48d8eff0",
    "ExecuteTime": {
     "end_time": "2024-04-17T22:25:06.511349Z",
     "start_time": "2024-04-17T22:25:06.510347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preforms Logistic Regression on the dataset\n",
    "lgr = LogisticRegression(max_iter=10000)\n",
    "lgr.fit(X_fetaures_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965737e2",
   "metadata": {
    "id": "965737e2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "85a331dc-5ec5-4188-9ad9-6f7d18f2a954"
   },
   "outputs": [],
   "source": [
    "# Training on the prediction\n",
    "predict_train = lgr.predict(X_fetaures_train)\n",
    "print(classification_report(predict_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5a1b0",
   "metadata": {
    "id": "79c5a1b0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "outputId": "8e156aeb-8c93-4e36-f6a5-a8a845e0ab62"
   },
   "outputs": [],
   "source": [
    "# Displays a confusion matrix based on the predicted vs actual values\n",
    "cm = confusion_matrix(y_train, predict_train)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Data"
   ],
   "metadata": {
    "id": "vNNL84WHESgF"
   },
   "id": "vNNL84WHESgF"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446e8e7",
   "metadata": {
    "id": "2446e8e7"
   },
   "outputs": [],
   "source": [
    "y_test = dp_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Removes stop words from test data and makes everything lowercase\n",
    "dp_test['no_stops'] = dp_test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "dp_test['no_stops'] = dp_test['no_stops'].str.lower()"
   ],
   "metadata": {
    "id": "onnvHHFdFPXP"
   },
   "id": "onnvHHFdFPXP",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creates a set of new features modified to be a bag of words using same training vectorizer (don't have to reformat testing!)\n",
    "X_features_test = create_bag_words(dp_test, vectorizer, \"no_stops\")"
   ],
   "metadata": {
    "id": "HHeXz1E8Ls1K"
   },
   "id": "HHeXz1E8Ls1K",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Gets label predictions from test data and printing results\n",
    "predict_test = lgr.predict(X_features_test)\n",
    "print(classification_report(predict_test, y_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtAN9UweFRPS",
    "outputId": "a59eda9f-2f6e-49c3-b27f-152ef77e91e2"
   },
   "id": "rtAN9UweFRPS",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Displays a confusion matrix based on the predicted vs actual values\n",
    "cm = confusion_matrix(y_test, predict_test)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "9Rp8-GSdGw4g",
    "outputId": "86d78641-fe97-42a6-b546-40dd017dc4ee"
   },
   "id": "9Rp8-GSdGw4g",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f8d648fdb299aa97"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
